# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
General utils
"""
# YOLOv5 é€šç”¨å·¥å…·ç±»ä»£ç 

import contextlib
import glob
import inspect
import logging
import math
import os
import platform
import random
import re
import shutil
import signal
import time
import urllib
from datetime import datetime
from itertools import repeat
from multiprocessing.pool import ThreadPool
from pathlib import Path
from subprocess import check_output
from typing import Optional
from zipfile import ZipFile

import cv2
import numpy as np
import pandas as pd
import pkg_resources as pkg
import torch
import torchvision
import yaml

from utils.downloads import gsutil_getsize
from utils.metrics import box_iou, fitness

# Settings
FILE = Path(__file__).resolve()
ROOT = FILE.parents[1]  # YOLOv5 root directory
DATASETS_DIR = ROOT.parent / 'datasets'  # YOLOv5 datasets directory
NUM_THREADS = min(8, max(1, os.cpu_count() - 1))  # number of YOLOv5 multiprocessing threads
AUTOINSTALL = str(os.getenv('YOLOv5_AUTOINSTALL', True)).lower() == 'true'  # global auto-install mode
VERBOSE = str(os.getenv('YOLOv5_VERBOSE', True)).lower() == 'true'  # global verbose mode
FONT = 'Arial.ttf'  # https://ultralytics.com/assets/Arial.ttf

# è®¾ç½®è¿è¡Œç›¸å…³çš„ä¸€äº›åŸºæœ¬çš„é…ç½®  Settings
# æ§åˆ¶printæ‰“å°torch.tensoræ ¼å¼è®¾ç½®  tensorç²¾åº¦ä¸º5(å°æ•°ç‚¹å5ä½)  æ¯è¡Œå­—ç¬¦æ•°ä¸º320ä¸ª  æ˜¾ç¤ºæ–¹æ³•ä¸ºlong
torch.set_printoptions(linewidth=320, precision=5, profile='long')
# æ§åˆ¶printæ‰“å°np.arrayæ ¼å¼è®¾ç½®  ç²¾åº¦ä¸º5  æ¯è¡Œå­—ç¬¦æ•°ä¸º320ä¸ª  format short g, %precision=5
np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})  # format short g, %precision=5
# pandasçš„æœ€å¤§æ˜¾ç¤ºè¡Œæ•°æ˜¯10
pd.options.display.max_columns = 10
# é˜»æ­¢opencvå‚ä¸å¤šçº¿ç¨‹(ä¸ Pytorchçš„ Dataloaderä¸å…¼å®¹)
cv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)
# ç¡®å®šæœ€å¤§çš„çº¿ç¨‹æ•° è¿™é‡Œè¢«é™åˆ¶åœ¨äº†8
os.environ['NUMEXPR_MAX_THREADS'] = str(NUM_THREADS)  # NumExpr max threads
os.environ['OMP_NUM_THREADS'] = str(NUM_THREADS)  # OpenMP max threads (PyTorch and SciPy)


def is_kaggle():
    # Is environment a Kaggle Notebook?
    try:
        assert os.environ.get('PWD') == '/kaggle/working'
        assert os.environ.get('KAGGLE_URL_BASE') == 'https://www.kaggle.com'
        return True
    except AssertionError:
        return False


def is_writeable(dir, test=False):
    # Return True if directory has write permissions, test opening a file with write permissions if test=True
    if test:  # method 1
        file = Path(dir) / 'tmp.txt'
        try:
            with open(file, 'w'):  # open file with write permissions
                pass
            file.unlink()  # remove file
            return True
        except OSError:
            return False
    else:  # method 2
        return os.access(dir, os.R_OK)  # possible issues on Windows


def set_logging(name=None, verbose=VERBOSE):
    """å¹¿æ³›ä½¿ç”¨åœ¨train.pyã€val.pyã€detect.pyç­‰æ–‡ä»¶çš„mainå‡½æ•°çš„ç¬¬ä¸€æ­¥
    å¯¹æ—¥å¿—çš„è®¾ç½®(formatã€level)ç­‰è¿›è¡Œåˆå§‹åŒ–
    """
    # Sets level and returns logger
    if is_kaggle():
        for h in logging.root.handlers:
            logging.root.removeHandler(h)  # remove all handlers associated with the root logger object
    rank = int(os.getenv('RANK', -1))  # rank in world for Multi-GPU trainings
    # è®¾ç½®æ—¥å¿—çº§åˆ«  rankä¸ä¸º-1æˆ–0æ—¶è®¾ç½®è¾“å‡ºçº§åˆ«levelä¸ºWARN  ä¸º-1æˆ–0æ—¶è®¾ç½®çº§åˆ«ä¸ºINFO
    level = logging.INFO if (verbose and rank in (-1, 0)) else logging.WARNING
    log = logging.getLogger(name)
    log.setLevel(level)
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter("%(message)s"))
    handler.setLevel(level)
    log.addHandler(handler)


set_logging()  # run before defining LOGGER
LOGGER = logging.getLogger("yolov5")  # define globally (used in train.py, val.py, detect.py, etc.)


def user_config_dir(dir='Ultralytics', env_var='YOLOV5_CONFIG_DIR'):
    # Return path of user configuration directory. Prefer environment variable if exists. Make dir if required.
    env = os.getenv(env_var)
    if env:
        path = Path(env)  # use environment variable
    else:
        cfg = {'Windows': 'AppData/Roaming', 'Linux': '.config', 'Darwin': 'Library/Application Support'}  # 3 OS dirs
        path = Path.home() / cfg.get(platform.system(), '')  # OS-specific config dir
        path = (path if is_writeable(path) else Path('/tmp')) / dir  # GCP and AWS lambda fix, only /tmp is writeable
    path.mkdir(exist_ok=True)  # make if required
    return path


CONFIG_DIR = user_config_dir()  # Ultralytics settings dir


class Profile(contextlib.ContextDecorator):
    # Usage: @Profile() decorator or 'with Profile():' context manager
    def __enter__(self):
        self.start = time.time()

    def __exit__(self, type, value, traceback):
        print(f'Profile results: {time.time() - self.start:.5f}s')


class Timeout(contextlib.ContextDecorator):
    # Usage: @Timeout(seconds) decorator or 'with Timeout(seconds):' context manager
    """ä»£ç ä¸­éƒ½æ˜¯ä½¿ç”¨åº“å‡½æ•°è‡ªå·±å®šä¹‰çš„timeout æ²¡ç”¨ç”¨è¿™ä¸ªè‡ªå®šä¹‰çš„timeoutå‡½æ•°
    è®¾ç½®ä¸€ä¸ªè¶…æ—¶å‡½æ•° å¦‚æœæŸä¸ªç¨‹åºæ‰§è¡Œè¶…æ—¶  å°±ä¼šè§¦å‘è¶…æ—¶å¤„ç†å‡½æ•°_timeout_handler è¿”å›è¶…æ—¶å¼‚å¸¸ä¿¡æ¯
    å¹¶æ²¡æœ‰ç”¨åˆ°  è¿™é‡Œé¢çš„timeoutéƒ½æ˜¯ç”¨pythonåº“å‡½æ•°å®ç°çš„ å¹¶ä¸éœ€è¦è‡ªå·±å¦å¤–å†™ä¸€ä¸ª
    ä½¿ç”¨: with timeout(seconds):  sleep(10)   æˆ–è€…   @timeout(seconds) decorator
    dealing with wandb login-options timeout issues as well as check_github() timeout issues
    """
    def __init__(self, seconds, *, timeout_msg='', suppress_timeout_errors=True):
        self.seconds = int(seconds)         # é™åˆ¶æ—¶é—´
        self.timeout_message = timeout_msg  # æŠ¥é”™ä¿¡æ¯
        self.suppress = bool(suppress_timeout_errors)

    def _timeout_handler(self, signum, frame):
        # è¶…æ—¶å¤„ç†å‡½æ•° ä¸€æ—¦è¶…æ—¶ å°±åœ¨secondsåå‘é€è¶…æ—¶ä¿¡æ¯
        raise TimeoutError(self.timeout_message)

    def __enter__(self):
        if platform.system() != 'Windows':  # not supported on Windows
            # signal.signal: è®¾ç½®ä¿¡å·å¤„ç†çš„å‡½æ•°_timeout_handler
            # æ‰§è¡Œæµè¿›å…¥withä¸­ä¼šæ‰§è¡Œ__enter__æ–¹æ³• å¦‚æœå‘ç”Ÿè¶…æ—¶, å°±ä¼šè§¦å‘è¶…æ—¶å¤„ç†å‡½æ•°_timeout_handler è¿”å›è¶…æ—¶å¼‚å¸¸ä¿¡æ¯
            signal.signal(signal.SIGALRM, self._timeout_handler)  # Set handler for SIGALRM
            # signal.alarm: è®¾ç½®å‘é€SIGALRMä¿¡å·çš„å®šæ—¶å™¨
            signal.alarm(self.seconds)  # start countdown for SIGALRM to be raised

    def __exit__(self, exc_type, exc_val, exc_tb):
        if platform.system() != 'Windows':
            # æ‰§è¡Œæµç¦»å¼€ with å—æ—¶(æ²¡æœ‰å‘ç”Ÿè¶…æ—¶), åˆ™è°ƒç”¨è¿™ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„__exit__æ–¹æ³•æ¥æ¸…ç†æ‰€ä½¿ç”¨çš„èµ„æº
            signal.alarm(0)  # Cancel SIGALRM if it's scheduled
            if self.suppress and exc_type is TimeoutError:  # Suppress TimeoutError
                return True


class WorkingDirectory(contextlib.ContextDecorator):
    # Usage: @WorkingDirectory(dir) decorator or 'with WorkingDirectory(dir):' context manager
    def __init__(self, new_dir):
        self.dir = new_dir  # new dir
        self.cwd = Path.cwd().resolve()  # current dir

    def __enter__(self):
        os.chdir(self.dir)

    def __exit__(self, exc_type, exc_val, exc_tb):
        os.chdir(self.cwd)


def try_except(func):
    # try-except function. Usage: @try_except decorator
    def handler(*args, **kwargs):
        try:
            func(*args, **kwargs)
        except Exception as e:
            print(e)

    return handler


def methods(instance):
    # Get class/instance methods
    return [f for f in dir(instance) if callable(getattr(instance, f)) and not f.startswith("__")]


def print_args(args: Optional[dict] = None, show_file=True, show_fcn=False):
    # Print function arguments (optional args dict)
    x = inspect.currentframe().f_back  # previous frame
    file, _, fcn, _, _ = inspect.getframeinfo(x)
    if args is None:  # get args automatically
        args, _, _, frm = inspect.getargvalues(x)
        args = {k: v for k, v in frm.items() if k in args}
    s = (f'{Path(file).stem}: ' if show_file else '') + (f'{fcn}: ' if show_fcn else '')
    LOGGER.info(colorstr(s) + ', '.join(f'{k}={v}' for k, v in args.items()))


def init_seeds(seed=0):
    """åœ¨trainå‡½æ•°çš„ä¸€å¼€å§‹è°ƒç”¨
    ç”¨äºè®¾ç½®ä¸€ç³»åˆ—çš„éšæœºæ•°ç§å­
    """
    # Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html
    # cudnn seed 0 settings are slower and more reproducible, else faster and less reproducible
    import torch.backends.cudnn as cudnn
    # è®¾ç½®éšæœºæ•° é’ˆå¯¹ä½¿ç”¨random.random()ç”Ÿæˆéšæœºæ•°çš„æ—¶å€™ç›¸åŒ
    random.seed(seed)
    # è®¾ç½®éšæœºæ•° é’ˆå¯¹ä½¿ç”¨np.random.rand()ç”Ÿæˆéšæœºæ•°çš„æ—¶å€™ç›¸åŒ
    np.random.seed(seed)
    torch.manual_seed(seed)
    cudnn.benchmark, cudnn.deterministic = (False, True) if seed == 0 else (True, False)


def intersect_dicts(da, db, exclude=()):
    # Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values
    return {k: v for k, v in da.items() if k in db and not any(x in k for x in exclude) and v.shape == db[k].shape}


def get_latest_run(search_dir='.'):
    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)
    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)
    return max(last_list, key=os.path.getctime) if last_list else ''


def is_docker():
    # Is environment a Docker container?
    return Path('/workspace').exists()  # or Path('/.dockerenv').exists()


def is_colab():
    # Is environment a Google Colab instance?
    try:
        import google.colab
        return True
    except ImportError:
        return False


def is_pip():
    # Is file in a pip package?
    return 'site-packages' in Path(__file__).resolve().parts


def is_ascii(s=''):
    # Is string composed of all ASCII (no UTF) characters? (note str().isascii() introduced in python 3.7)
    s = str(s)  # convert list, tuple, None, etc. to str
    return len(s.encode().decode('ascii', 'ignore')) == len(s)


def is_chinese(s='äººå·¥æ™ºèƒ½'):
    # Is string composed of any Chinese characters?
    return True if re.search('[\u4e00-\u9fff]', str(s)) else False


def emojis(str=''):
    # Return platform-dependent emoji-safe version of string
    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str


def file_age(path=__file__):
    # Return days since last file update
    dt = (datetime.now() - datetime.fromtimestamp(Path(path).stat().st_mtime))  # delta
    return dt.days  # + dt.seconds / 86400  # fractional days


def file_update_date(path=__file__):
    # Return human-readable file modification date, i.e. '2021-3-26'
    t = datetime.fromtimestamp(Path(path).stat().st_mtime)
    return f'{t.year}-{t.month}-{t.day}'


def file_size(path):
    # Return file/dir size (MB)
    mb = 1 << 20  # bytes to MiB (1024 ** 2)
    path = Path(path)
    if path.is_file():
        return path.stat().st_size / mb
    elif path.is_dir():
        return sum(f.stat().st_size for f in path.glob('**/*') if f.is_file()) / mb
    else:
        return 0.0


def check_online():
    # Check internet connectivity
    """åœ¨ä¸‹é¢çš„check_git_statusã€check_requirementsç­‰å‡½æ•°ä¸­ä½¿ç”¨
    æ£€æŸ¥å½“å‰ä¸»æœºç½‘ç»œè¿æ¥æ˜¯å¦å¯ç”¨
    """
    import socket  # å¯¼å…¥socketæ¨¡å— å¯è§£å†³åŸºäºtcpå’Œucpåè®®çš„ç½‘ç»œä¼ è¾“

    try:
        # è¿æ¥åˆ°ä¸€ä¸ªip åœ°å€addr("1.1.1.1")çš„TCPæœåŠ¡ä¸Š, ç«¯å£å·port=443 timeout=5 æ—¶é™5ç§’ å¹¶è¿”å›ä¸€ä¸ªæ–°çš„å¥—æ¥å­—å¯¹è±¡
        socket.create_connection(("1.1.1.1", 443), 5)  # check host accessibility
        # æ²¡å‘ç°ä»€ä¹ˆå¼‚å¸¸, è¿æ¥æˆåŠŸ, æœ‰ç½‘, å°±è¿”å›True
        return True
    except OSError:
        return False


def git_describe(path=ROOT):  # path must be a directory
    """ç”¨åœ¨select_device
    ç”¨äºè¿”å›pathæ–‡ä»¶å¯è¯»çš„gitæè¿°  return human-readable git description  i.e. v5.0-5-g3e25f1e
    https://git-scm.com/docs/git-describe
    path: éœ€è¦åœ¨gitä¸­æŸ¥è¯¢ï¼ˆæ–‡ä»¶æè¿°ï¼‰çš„æ–‡ä»¶å  é»˜è®¤å½“å‰æ–‡ä»¶çš„çˆ¶è·¯å¾„
    """
    # Return human-readable git description, i.e. v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe
    try:
        assert (Path(path) / '.git').is_dir()
        return check_output(f'git -C {path} describe --tags --long --always', shell=True).decode()[:-1]
    except Exception:
        return ''


@try_except
@WorkingDirectory(ROOT)
def check_git_status():
    """ç”¨åœ¨train.pyçš„mainå‡½æ•°çš„ä¸€å¼€å§‹
    æ£€æŸ¥å½“å‰ä»£ç ç‰ˆæœ¬æ˜¯å¦æ˜¯æœ€æ–°çš„   å¦‚æœä¸æ˜¯æœ€æ–°çš„ ä¼šæç¤ºä½¿ç”¨git pullå‘½ä»¤è¿›è¡Œå‡çº§
    """
    # Recommend 'git pull' if code is out of date
    msg = ', for updates see https://github.com/ultralytics/yolov5'
    s = colorstr('github: ')  # string
    # æ£€æŸ¥ç”µè„‘æœ‰æ²¡æœ‰å®‰è£…gitä»“åº“  æ²¡æœ‰å®‰è£…ç›´æ¥æŠ¥å¼‚å¸¸å¹¶è¾“å‡ºå¼‚å¸¸ä¿¡æ¯
    assert Path('.git').exists(), s + 'skipping check (not a git repository)' + msg
    # æ£€æŸ¥ç”µè„‘ç³»ç»Ÿæœ‰æ²¡æœ‰å®‰è£…dockerç¯å¢ƒå˜é‡ æ²¡æœ‰ç›´æ¥æŠ¥å¼‚å¸¸å¹¶è¾“å‡ºå¼‚å¸¸ä¿¡æ¯
    assert not is_docker(), s + 'skipping check (Docker image)' + msg
    # æ£€æŸ¥ä¸»æœºæ˜¯å¦è”ç½‘
    assert check_online(), s + 'skipping check (offline)' + msg

    # åˆ›å»ºcmdå‘½ä»¤
    cmd = 'git fetch && git config --get remote.origin.url'
    # å¹¶åˆ›å»ºå­è¿›ç¨‹è¿›è¡Œæ‰§è¡Œcmdå‘½ä»¤  è¿”å›æ‰§è¡Œç»“æœ  æ—¶é™5ç§’
    url = check_output(cmd, shell=True, timeout=5).decode().strip().rstrip('.git')  # git fetch
    branch = check_output('git rev-parse --abbrev-ref HEAD', shell=True).decode().strip()  # checked out
    n = int(check_output(f'git rev-list {branch}..origin/master --count', shell=True))  # commits behind
    # n>0 è¯´æ˜å½“å‰ç‰ˆæœ¬ä¹‹åè¿˜æœ‰commit å› æ­¤å½“å‰ç‰ˆæœ¬ä¸æ˜¯æœ€æ–°çš„ sä¸ºè¾“å‡ºçš„ç›¸å…³æç¤º
    if n > 0:
        # å¦‚æœä¸æ˜¯æœ€æ–°  æå‡å­—ç¬¦s: WARNING...
        s += f"âš ï¸ YOLOv5 is out of date by {n} commit{'s' * (n > 1)}. Use `git pull` or `git clone {url}` to update."
    else:
        # å·²ç»æ˜¯æœ€æ–°
        s += f'up to date with {url} âœ…'
    LOGGER.info(emojis(s))  # emoji-safe


def check_python(minimum='3.7.0'):
    """ç”¨åœ¨ä¸‹é¢çš„å‡½æ•°check_requirementsä¸­
    æ£€æŸ¥å½“å‰çš„ç‰ˆæœ¬å·æ˜¯å¦æ»¡è¶³æœ€å°ç‰ˆæœ¬å·minimum
    Check current python version vs. required python version
    """
    # Check current python version vs. required python version
    check_version(platform.python_version(), minimum, name='Python ', hard=True)


def check_version(current='0.0.0', minimum='0.0.0', name='version ', pinned=False, hard=False, verbose=False):
    # Check version vs. required version
    current, minimum = (pkg.parse_version(x) for x in (current, minimum))
    result = (current == minimum) if pinned else (current >= minimum)  # bool
    s = f'{name}{minimum} required by YOLOv5, but {name}{current} is currently installed'  # string
    if hard:
        assert result, s  # assert min requirements met
    if verbose and not result:
        LOGGER.warning(s)
    return result


@try_except
def check_requirements(requirements=ROOT / 'requirements.txt', exclude=(), install=True, cmds=()):
    """ç”¨åœ¨train.pyã€val.pyã€detect.pyç­‰æ–‡ä»¶
    ç”¨äºæ£€æŸ¥å·²ç»å®‰è£…çš„åŒ…æ˜¯å¦æ»¡è¶³requirementså¯¹åº”txtæ–‡ä»¶çš„è¦æ±‚
    Check installed dependencies meet requirements (pass *.txt file or list of packages)
    """
    # Check installed dependencies meet requirements (pass *.txt file or list of packages)
    prefix = colorstr('red', 'bold', 'requirements:')
    check_python()  # check python version
    # è§£ærequirements.txtä¸­çš„æ‰€æœ‰åŒ… è§£ææˆlist é‡Œé¢å­˜æ”¾ç€ä¸€ä¸ªä¸ªçš„pkg_resources.Requirementç±»
    # å¦‚: ['matplotlib>=3.2.2', 'numpy>=1.18.5', â€¦â€¦]
    if isinstance(requirements, (str, Path)):  # requirements.txt file
        # å°†strå­—ç¬¦ä¸²requirementsè½¬æ¢æˆè·¯å¾„requirements
        file = Path(requirements)
        assert file.exists(), f"{prefix} {file.resolve()} not found, check failed."
        with file.open() as f:
            requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(f) if x.name not in exclude]
    else:  # list or tuple of packages
        requirements = [x for x in requirements if x not in exclude]

    n = 0  # number of packages updates
    for i, r in enumerate(requirements):
        try:
            pkg.require(r)
        except Exception:  # DistributionNotFound or VersionConflict if requirements not met
            s = f"{prefix} {r} not found and is required by YOLOv5"
            if install and AUTOINSTALL:  # check environment variable
                LOGGER.info(f"{s}, attempting auto-update...")
                try:
                    assert check_online(), f"'pip install {r}' skipped (offline)"
                    LOGGER.info(check_output(f"pip install '{r}' {cmds[i] if cmds else ''}", shell=True).decode())
                    n += 1
                except Exception as e:
                    LOGGER.warning(f'{prefix} {e}')
            else:
                LOGGER.info(f'{s}. Please install and rerun your command.')

    if n:  # if packages updated
        source = file.resolve() if 'file' in locals() else requirements
        s = f"{prefix} {n} package{'s' * (n > 1)} updated per {source}\n" \
            f"{prefix} âš ï¸ {colorstr('bold', 'Restart runtime or rerun command for updates to take effect')}\n"
        LOGGER.info(emojis(s))


def check_img_size(imgsz, s=32, floor=0):
    """è¿™ä¸ªå‡½æ•°ä¸»è¦ç”¨äºtrain.pyä¸­å’Œdetect.pyä¸­  ç”¨æ¥æ£€æŸ¥å›¾ç‰‡çš„é•¿å®½æ˜¯å¦ç¬¦åˆè§„å®š
    æ£€æŸ¥img_sizeæ˜¯å¦èƒ½è¢«sæ•´é™¤ï¼Œè¿™é‡Œé»˜è®¤sä¸º32  è¿”å›å¤§äºç­‰äºimg_sizeä¸”æ˜¯sçš„æœ€å°å€æ•°
    Verify img_size is a multiple of stride s
    """
    # å–å¤§äºç­‰äºxçš„æœ€å°å€¼ä¸”è¯¥å€¼èƒ½è¢«divisoræ•´é™¤
    # Verify image size is a multiple of stride s in each dimension
    if isinstance(imgsz, int):  # integer i.e. img_size=640
        new_size = max(make_divisible(imgsz, int(s)), floor)
    else:  # list i.e. img_size=[640, 480]
        imgsz = list(imgsz)  # convert to list if tuple
        new_size = [max(make_divisible(x, int(s)), floor) for x in imgsz]
    if new_size != imgsz:
        LOGGER.warning(f'WARNING: --img-size {imgsz} must be multiple of max stride {s}, updating to {new_size}')
    return new_size


def check_imshow():
    """ç”¨åœ¨detect.pyä¸­  ä½¿ç”¨webcamçš„æ—¶å€™è°ƒç”¨
    æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦å¯ä»¥ä½¿ç”¨opencv.imshowæ˜¾ç¤ºå›¾ç‰‡
    ä¸»è¦æœ‰ä¸¤ç‚¹é™åˆ¶: Dockerç¯å¢ƒ + Google Colabç¯å¢ƒ
    """
    # Check if environment supports image displays
    try:
        # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ˜¯ä¸€ä¸ªDockerç¯å¢ƒ cv2.imshow()ä¸èƒ½å†dockerç¯å¢ƒä¸­ä½¿ç”¨
        assert not is_docker(), 'cv2.imshow() is disabled in Docker environments'
        # æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ˜¯ä¸€ä¸ªGoogle Colabç¯å¢ƒ cv2.imshow()ä¸èƒ½åœ¨Google Colabç¯å¢ƒä¸­ä½¿ç”¨
        assert not is_colab(), 'cv2.imshow() is disabled in Google Colab environments'
        # åˆå§‹åŒ–ä¸€å¼ å›¾ç‰‡æ£€æŸ¥ä¸‹opencvæ˜¯å¦å¯ç”¨
        cv2.imshow('test', np.zeros((1, 1, 3)))
        cv2.waitKey(1)
        cv2.destroyAllWindows()
        cv2.waitKey(1)
        return True
    except Exception as e:
        LOGGER.warning(f'WARNING: Environment does not support cv2.imshow() or PIL Image.show() image displays\n{e}')
        return False


def check_suffix(file='yolov5s.pt', suffix=('.pt',), msg=''):
    # Check file(s) for acceptable suffix åç¼€
    if file and suffix:
        if isinstance(suffix, str):
            suffix = [suffix]
        for f in file if isinstance(file, (list, tuple)) else [file]:
            s = Path(f).suffix.lower()  # file suffix
            if len(s):
                assert s in suffix, f"{msg}{f} acceptable suffix is {suffix}"


def check_yaml(file, suffix=('.yaml', '.yml')):
    # Search/download YAML file (if necessary) and return path, checking suffix
    return check_file(file, suffix)


def check_file(file, suffix=''):
    """ç”¨åœ¨train.pyã€detect.pyã€test.pyç­‰æ–‡ä»¶ä¸­æ£€æŸ¥æœ¬åœ°æœ‰æ²¡æœ‰è¿™ä¸ªæ–‡ä»¶
    æ£€æŸ¥ç›¸å…³æ–‡ä»¶è·¯å¾„èƒ½å¦æ‰¾åˆ°æ–‡ä»¶ å¹¶è¿”å›æ–‡ä»¶å
    Search/download file (if necessary) and return path
    """
    # Search/download file (if necessary) and return path
    check_suffix(file, suffix)  # optional
    file = str(file)  # convert to str()
    if Path(file).is_file() or file == '':  # exists
        return file
    # å¦‚æœä¼ è¿›æ¥çš„ä»¥ 'http:/' æˆ–è€… 'https:/' å¼€å¤´çš„urlåœ°å€, å°±ä¸‹è½½
    elif file.startswith(('http:/', 'https:/')):  # download
        url = str(Path(file)).replace(':/', '://')  # Pathlib turns :// -> :/
        file = Path(urllib.parse.unquote(file).split('?')[0]).name  # '%2F' to '/', split https://url.com/file.txt?auth
        if Path(file).is_file():
            LOGGER.info(f'Found {url} locally at {file}')  # file already exists
        else:
            LOGGER.info(f'Downloading {url} to {file}...')
            # ä½¿ç”¨torch.hub.download_url_to_fileä»urlåœ°å€ä¸Šä¸­ä¸‹è½½æ–‡ä»¶åä¸ºfileçš„æ–‡ä»¶
            torch.hub.download_url_to_file(url, file)
            # æ£€æŸ¥æ˜¯å¦ä¸‹è½½æˆåŠŸ
            assert Path(file).exists() and Path(file).stat().st_size > 0, f'File download failed: {url}'  # check
        return file
    else:  # search
        # å¦åˆ™, ä¼ è¿›æ¥çš„å°±æ˜¯å½“å‰é¡¹ç›®ä¸‹çš„ä¸€ä¸ªå…¨å±€è·¯å¾„ æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶å è¿”å›ç¬¬ä¸€ä¸ª
        # glob.glob: åŒ¹é…å½“å‰é¡¹ç›®ä¸‹çš„æ‰€æœ‰é¡¹ç›® è¿”å›æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶files
        files = []
        for d in 'data', 'models', 'utils':  # search directories
            files.extend(glob.glob(str(ROOT / d / '**' / file), recursive=True))  # find file
        assert len(files), f'File not found: {file}'  # assert file was found
        assert len(files) == 1, f"Multiple files match '{file}', specify exact path: {files}"  # assert unique
        return files[0]  # return file


def check_font(font=FONT, progress=False):
    # Download font to CONFIG_DIR if necessary
    font = Path(font)
    file = CONFIG_DIR / font.name
    if not font.exists() and not file.exists():
        url = "https://ultralytics.com/assets/" + font.name
        LOGGER.info(f'Downloading {url} to {file}...')
        torch.hub.download_url_to_file(url, str(file), progress=progress)


def check_dataset(data, autodownload=True):
    # Download and/or unzip dataset if not found locally
    # Usage: https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128_with_yaml.zip

    # Download (optional)
    """ç”¨åœ¨train.pyå’Œdetect.pyä¸­ æ£€æŸ¥æœ¬åœ°æœ‰æ²¡æœ‰æ•°æ®é›†
    æ£€æŸ¥æ•°æ®é›† å¦‚æœæœ¬åœ°æ²¡æœ‰åˆ™ä»torchåº“ä¸­ä¸‹è½½å¹¶è§£å‹æ•°æ®é›†
    :params data: æ˜¯ä¸€ä¸ªè§£æè¿‡çš„data_dict   len=7
                  ä¾‹å¦‚: ['path'='../datasets/coco128', 'train','val', 'test', 'nc', 'names', 'download']
    :params autodownload: å¦‚æœæœ¬åœ°æ²¡æœ‰æ•°æ®é›†æ˜¯å¦éœ€è¦ç›´æ¥ä»torchåº“ä¸­ä¸‹è½½æ•°æ®é›†  é»˜è®¤True
    """
    extract_dir = ''
    if isinstance(data, (str, Path)) and str(data).endswith('.zip'):  # i.e. gs://bucket/dir/coco128.zip
        download(data, dir=DATASETS_DIR, unzip=True, delete=False, curl=False, threads=1)
        data = next((DATASETS_DIR / Path(data).stem).rglob('*.yaml'))
        extract_dir, autodownload = data.parent, False

    # Read yaml (optional)
    if isinstance(data, (str, Path)):
        with open(data, errors='ignore') as f:
            data = yaml.safe_load(f)  # dictionary

    # Resolve paths
    path = Path(extract_dir or data.get('path') or '')  # optional 'path' default to '.'
    if not path.is_absolute():
        path = (ROOT / path).resolve()
    for k in 'train', 'val', 'test':
        if data.get(k):  # prepend path
            data[k] = str(path / data[k]) if isinstance(data[k], str) else [str(path / x) for x in data[k]]

    # Parse yaml
    assert 'nc' in data, "Dataset 'nc' key missing."
    if 'names' not in data:
        data['names'] = [f'class{i}' for i in range(data['nc'])]  # assign class names if missing
    # train: è®­ç»ƒè·¯å¾„  '..\\datasets\\coco128\\images\\train2017'
    # val: éªŒè¯è·¯å¾„    '..\\datasets\\coco128\\images\\train2017'
    # test: æµ‹è¯•è·¯å¾„   None
    # s: ä¸‹è½½åœ°å€      'https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip'
    train, val, test, s = (data.get(x) for x in ('train', 'val', 'test', 'download'))
    if val:
        # path.resolve() è¯¥æ–¹æ³•å°†ä¸€äº›çš„ è·¯å¾„/è·¯å¾„æ®µ è§£æä¸ºç»å¯¹è·¯å¾„
        # val: [WindowsPath('E:/yolo_v5/datasets/coco128/images/train2017')]
        val = [Path(x).resolve() for x in (val if isinstance(val, list) else [val])]  # val path
        # å¦‚æœvalä¸å­˜åœ¨ è¯´æ˜æœ¬åœ°ä¸å­˜åœ¨æ•°æ®é›†
        if not all(x.exists() for x in val):
            LOGGER.info(emojis('\nDataset not found âš , missing paths %s' % [str(x) for x in val if not x.exists()]))
            # å¦‚æœä¸‹è½½åœ°å€så’Œä¸‹è½½æ ‡è®°(flag)autodownloadä¸ä¸ºç©º, å°±ç›´æ¥ä¸‹è½½
            if s and autodownload:  # download script
                t = time.time()
                root = path.parent if 'path' in data else '..'  # unzip directory i.e. '../'
                # å¦‚æœä¸‹è½½åœ°å€sæ˜¯httpå¼€å¤´å°±ä»urlä¸­ä¸‹è½½æ•°æ®é›†
                if s.startswith('http') and s.endswith('.zip'):  # URL
                    # f: å¾—åˆ°ä¸‹è½½æ–‡ä»¶çš„æ–‡ä»¶å filename
                    f = Path(s).name  # filename
                    LOGGER.info(f'Downloading {s} to {f}...')
                    # å¼€å§‹ä¸‹è½½ åˆ©ç”¨torch.hub.download_url_to_fileå‡½æ•°ä»sè·¯å¾„ä¸­ä¸‹è½½æ–‡ä»¶åä¸ºfçš„æ–‡ä»¶
                    torch.hub.download_url_to_file(s, f)
                    Path(root).mkdir(parents=True, exist_ok=True)  # create root
                    ZipFile(f).extractall(path=root)  # unzip
                    Path(f).unlink()  # remove zip
                    # æ‰§è¡Œè§£å‹å‘½å å°†æ–‡ä»¶fè§£å‹åˆ°rootåœ°å€ è§£å‹åæ–‡ä»¶åä¸ºf
                    r = None  # success
                # å¦‚æœä¸‹è½½åœ°å€sæ˜¯bashå¼€å¤´å°±ä½¿ç”¨bashæŒ‡ä»¤ä¸‹è½½æ•°æ®é›†
                elif s.startswith('bash '):  # bash script
                    LOGGER.info(f'Running {s} ...')
                    # ä½¿ç”¨bashå‘½ä»¤ä¸‹è½½
                    r = os.system(s)
                # å¦åˆ™ä¸‹è½½åœ°å€å°±æ˜¯ä¸€ä¸ªpythonè„šæœ¬ æ‰§è¡Œpythonè„šæœ¬ä¸‹è½½æ•°æ®é›†
                else:  # python script
                    r = exec(s, {'yaml': data})  # return None
                dt = f'({round(time.time() - t, 1)}s)'
                s = f"success âœ… {dt}, saved to {colorstr('bold', root)}" if r in (0, None) else f"failure {dt} âŒ"
                LOGGER.info(emojis(f"Dataset download {s}"))
            else:
                # ä¸‹è½½åœ°å€ä¸ºç©º æˆ–è€…ä¸éœ€è¦ä¸‹è½½ æ ‡è®°(flag)autodownload
                raise Exception(emojis('Dataset not found âŒ'))

    check_font('Arial.ttf' if is_ascii(data['names']) else 'Arial.Unicode.ttf', progress=True)  # download fonts
    return data  # dictionary


def url2file(url):
    # Convert URL to filename, i.e. https://url.com/file.txt?auth -> file.txt
    url = str(Path(url)).replace(':/', '://')  # Pathlib turns :// -> :/
    file = Path(urllib.parse.unquote(url)).name.split('?')[0]  # '%2F' to '/', split https://url.com/file.txt?auth
    return file


def download(url, dir='.', unzip=True, delete=True, curl=False, threads=1, retry=3):
    # Multi-threaded file download and unzip function, used in data.yaml for autodownload
    """åœ¨voc.yamlä¸­ä¸‹è½½æ•°æ®é›†
    Multi-threaded file download and unzip function
    :params url: ä¸‹è½½æ–‡ä»¶çš„urlåœ°å€
    :params dir: ä¸‹è½½ä¸‹æ¥æ–‡ä»¶ä¿å­˜çš„ç›®å½•
    :params unzip: ä¸‹è½½åæ–‡ä»¶æ˜¯å¦éœ€è¦è§£å‹
    :params delete: è§£å‹ååŸæ–‡ä»¶(æœªè§£å‹)æ˜¯å¦éœ€è¦åˆ é™¤
    :params curl: æ˜¯å¦ä½¿ç”¨cmd curlè¯­å¥ä¸‹è½½æ–‡ä»¶  Falseå°±ä½¿ç”¨torch.hubä¸‹è½½
    :params threads: ä¸‹è½½ä¸€ä¸ªæ–‡ä»¶éœ€è¦çš„çº¿ç¨‹æ•°
    """
    def download_one(url, dir):
        # Download 1 file
        """
        Download 1 file
        :params url: æ–‡ä»¶ä¸‹è½½åœ°å€  Path(url).name=æ–‡ä»¶å
        :params dir: æ–‡ä»¶ä¿å­˜çš„ç›®å½•
        """
        success = True
        f = dir / Path(url).name  # filename
        if Path(url).is_file():  # exists in current path
            Path(url).rename(f)  # move to dir
        elif not f.exists():
            LOGGER.info(f'Downloading {url} to {f}...')
            for i in range(retry + 1):
                if curl:
                    s = 'sS' if threads > 1 else ''  # silent
                    r = os.system(f"curl -{s}L '{url}' -o '{f}' --retry 9 -C -")  # curl download
                    success = r == 0
                else:
                    torch.hub.download_url_to_file(url, f, progress=threads == 1)  # torch download
                    success = f.is_file()
                if success:
                    break
                elif i < retry:
                    LOGGER.warning(f'Download failure, retrying {i + 1}/{retry} {url}...')
                else:
                    LOGGER.warning(f'Failed to download {url}...')

        if unzip and success and f.suffix in ('.zip', '.gz'):
            LOGGER.info(f'Unzipping {f}...')
            if f.suffix == '.zip':
                ZipFile(f).extractall(path=dir)  # unzip
            elif f.suffix == '.gz':
                os.system(f'tar xfz {f} --directory {f.parent}')  # unzip
            if delete:
                f.unlink()  # remove zip

    dir = Path(dir)
    dir.mkdir(parents=True, exist_ok=True)  # make directory
    if threads > 1:  # ä½¿ç”¨çº¿ç¨‹æ± 
        # å®šä¹‰äº†ä¸€ä¸ªçº¿ç¨‹æ± , æœ€å¤šåˆ›å»ºthreadsä¸ªçº¿ç¨‹
        pool = ThreadPool(threads)
        # è¿›ç¨‹æ± ä¸­çš„è¯¥æ–¹æ³•ä¼šå°† iterable å‚æ•°ä¼ å…¥çš„å¯è¿­ä»£å¯¹è±¡åˆ†æˆ chunksize ä»½ä¼ é€’ç»™ä¸åŒçš„è¿›ç¨‹æ¥å¤„ç†ã€‚
        pool.imap(lambda x: download_one(*x), zip(url, repeat(dir)))  # multi-threaded
        pool.close()
        pool.join()
    else:
        for u in [url] if isinstance(url, (str, Path)) else url:
            download_one(u, dir)


def make_divisible(x, divisor):
    # Returns nearest x divisible by divisor
    if isinstance(divisor, torch.Tensor):
        divisor = int(divisor.max())  # to int
    return math.ceil(x / divisor) * divisor


def clean_str(s):
    # Cleans a string by replacing special characters with underscore _
    """åœ¨datasets.pyä¸­çš„LoadStreamsç±»ä¸­è¢«è°ƒç”¨
    å­—ç¬¦ä¸²sé‡Œåœ¨patternä¸­å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿_  æ³¨æ„patternä¸­[]ä¸èƒ½çœ
    Cleans a string by replacing special characters with underscore _
    """
    # re: ç”¨æ¥åŒ¹é…å­—ç¬¦ä¸²ï¼ˆåŠ¨æ€ã€æ¨¡ç³Šï¼‰çš„æ¨¡å—  æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—
    # pattern: è¡¨ç¤ºæ­£åˆ™ä¸­çš„æ¨¡å¼å­—ç¬¦ä¸²  repl: å°±æ˜¯replacementçš„å­—ç¬¦ä¸²  string: è¦è¢«å¤„ç†, è¦è¢«æ›¿æ¢çš„é‚£ä¸ªstringå­—ç¬¦ä¸²
    # æ‰€ä»¥è¿™å¥è¯æ‰§è¡Œçš„æ˜¯å°†å­—ç¬¦ä¸²sé‡Œåœ¨patternä¸­çš„å­—ç¬¦ä¸²æ›¿æ¢ä¸º "_"
    return re.sub(pattern="[|@#!Â¡Â·$â‚¬%&()=?Â¿^*;:,Â¨Â´><+]", repl="_", string=s)


def one_cycle(y1=0.0, y2=1.0, steps=100):
    # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf
    """ç”¨åœ¨train.pyä¸­çš„å­¦ä¹ ç‡è¡°å‡ç­–ç•¥æ¨¡å—
    one_cycle lr  lrå…ˆå¢åŠ , å†å‡å°‘, å†ä»¥æ›´å°çš„æ–œç‡å‡å°‘
    è®ºæ–‡: https://arxiv.org/pdf/1803.09820.pdf
    """
    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1


def colorstr(*input):
    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')
    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string
    colors = {
        'black': '\033[30m',  # basic colors
        'red': '\033[31m',
        'green': '\033[32m',
        'yellow': '\033[33m',
        'blue': '\033[34m',
        'magenta': '\033[35m',
        'cyan': '\033[36m',
        'white': '\033[37m',
        'bright_black': '\033[90m',  # bright colors
        'bright_red': '\033[91m',
        'bright_green': '\033[92m',
        'bright_yellow': '\033[93m',
        'bright_blue': '\033[94m',
        'bright_magenta': '\033[95m',
        'bright_cyan': '\033[96m',
        'bright_white': '\033[97m',
        'end': '\033[0m',  # misc
        'bold': '\033[1m',
        'underline': '\033[4m'}
    return ''.join(colors[x] for x in args) + f'{string}' + colors['end']


def labels_to_class_weights(labels, nc=80):
    # Get class weights (inverse frequency) from training labels
    """ç”¨åœ¨train.pyä¸­  å¾—åˆ°æ¯ä¸ªç±»åˆ«çš„æƒé‡   æ ‡ç­¾é¢‘ç‡é«˜çš„ç±»æƒé‡ä½
    ä»è®­ç»ƒ(gt)æ ‡ç­¾è·å¾—æ¯ä¸ªç±»çš„æƒé‡  æ ‡ç­¾é¢‘ç‡é«˜çš„ç±»æƒé‡ä½
    Get class weights (inverse frequency) from training labels
    :params labels: gtæ¡†çš„æ‰€æœ‰çœŸå®æ ‡ç­¾labels
    :params nc: æ•°æ®é›†çš„ç±»åˆ«æ•°
    :return torch.from_numpy(weights): æ¯ä¸€ä¸ªç±»åˆ«æ ¹æ®labelså¾—åˆ°çš„å æ¯”(æ¬¡æ•°è¶Šå¤šæƒé‡è¶Šå°) tensor
    """
    if labels[0] is None:  # no labels loaded
        return torch.Tensor()

    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO
    # classes: æ‰€æœ‰æ ‡ç­¾å¯¹åº”çš„ç±»åˆ«labels   labels[:, 0]: ç±»åˆ«   .astype(np.int): å–æ•´
    classes = labels[:, 0].astype(np.int)  # labels = [class xywh]
    # weight: è¿”å›æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•° [1, nc]
    weights = np.bincount(classes, minlength=nc)  # occurrences per class

    # Prepend gridpoint count (for uCE training)
    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image
    # weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start

    # å°†å‡ºç°æ¬¡æ•°ä¸º0çš„ç±»åˆ«æƒé‡å…¨éƒ¨å–1  replace empty bins with 1
    weights[weights == 0] = 1  # replace empty bins with 1
    # å…¶ä»–æ‰€æœ‰çš„ç±»åˆ«çš„æƒé‡å…¨éƒ¨å–æ¬¡æ•°çš„å€’æ•°  number of targets per class
    weights = 1 / weights  # number of targets per class
    # normalize æ±‚å‡ºæ¯ä¸€ç±»åˆ«çš„å æ¯”
    weights /= weights.sum()  # normalize
    return torch.from_numpy(weights)   # numpy -> tensor


def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):
    # Produces image weights based on class_weights and image contents
    """ç”¨åœ¨train.pyä¸­ åˆ©ç”¨ä¸Šé¢å¾—åˆ°çš„æ¯ä¸ªç±»åˆ«çš„æƒé‡å¾—åˆ°æ¯ä¸€å¼ å›¾ç‰‡çš„æƒé‡  å†å¯¹å›¾ç‰‡è¿›è¡ŒæŒ‰æƒé‡è¿›è¡Œé‡‡æ ·
    é€šè¿‡æ¯å¼ å›¾ç‰‡çœŸå®gtæ¡†çš„çœŸå®æ ‡ç­¾labelså’Œä¸Šä¸€æ­¥labels_to_class_weightså¾—åˆ°çš„æ¯ä¸ªç±»åˆ«çš„æƒé‡è¿›è¡Œé‡‡æ ·
    Produces image weights based on class_weights and image contents
    :params labels: æ¯å¼ å›¾ç‰‡çœŸå®gtæ¡†çš„çœŸå®æ ‡ç­¾
    :params nc: æ•°æ®é›†çš„ç±»åˆ«æ•° é»˜è®¤80
    :params class_weights: [80] ä¸Šä¸€æ­¥labels_to_class_weightså¾—åˆ°çš„æ¯ä¸ªç±»åˆ«çš„æƒé‡
    """
    # class_counts: æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•°  [num_labels, nc]  æ¯ä¸€è¡Œæ˜¯å½“å‰è¿™å¼ å›¾ç‰‡æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•°  num_labels=å›¾ç‰‡æ•°é‡=labelæ•°é‡
    class_counts = np.array([np.bincount(x[:, 0].astype(np.int), minlength=nc) for x in labels])
    # [80] -> [1, 80]
    # æ•´ä¸ªæ•°æ®é›†çš„æ¯ä¸ªç±»åˆ«æƒé‡[1, 80] *  æ¯å¼ å›¾ç‰‡çš„æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•°[num_labels, 80] = å¾—åˆ°æ¯ä¸€å¼ å›¾ç‰‡æ¯ä¸ªç±»å¯¹åº”çš„æƒé‡[128, 80]
    # å¦å¤–æ³¨æ„: è¿™é‡Œä¸æ˜¯çŸ©é˜µç›¸ä¹˜, æ˜¯å…ƒç´ ç›¸ä¹˜ [1, 80] å’Œæ¯ä¸€è¡Œå›¾ç‰‡çš„æ¯ä¸ªç±»åˆ«å‡ºç°çš„æ¬¡æ•° [1, 80] åˆ†åˆ«æŒ‰å…ƒç´ ç›¸ä¹˜
    # å†sum(1): æŒ‰è¡Œç›¸åŠ   å¾—åˆ°æœ€ç»ˆimage_weights: å¾—åˆ°æ¯ä¸€å¼ å›¾ç‰‡å¯¹åº”çš„é‡‡æ ·æƒé‡[128]
    image_weights = (class_weights.reshape(1, nc) * class_counts).sum(1)
    # index = random.choices(range(n), weights=image_weights, k=1)  # weight image sample
    return image_weights


def coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)
    """ç”¨åœ¨test.pyä¸­   ä»80ç±»æ˜ å°„åˆ°91ç±»çš„cocoç´¢å¼• å–å¾—å¯¹åº”çš„class id
    å°†80ä¸ªç±»çš„cocoç´¢å¼•æ¢æˆ91ç±»çš„cocoç´¢å¼•
    :return x: ä¸º80ç±»çš„æ¯ä¸€ç±»åœ¨91ç±»ä¸­çš„ä½ç½®
    """
    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/
    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\n')
    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\n')
    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco
    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet
    x = [
        1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34,
        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,
        64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]
    return x


def xyxy2xywh(x):
    # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where xy1=top-left, xy2=bottom-right
    """"ç”¨åœ¨detect.pyå’Œtest.pyä¸­   æ“ä½œæœ€å, å°†é¢„æµ‹ä¿¡æ¯ä»xyxyæ ¼å¼è½¬ä¸ºxywhæ ¼å¼ å†ä¿å­˜
    Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where x1y1=top-left, x2y2=bottom-right
    :params x: [n, x1y1x2y2] (x1, y1): å·¦ä¸Šè§’   (x2, y2): å³ä¸‹è§’
    :return y: [n, xywh] (x, y): ä¸­å¿ƒç‚¹  wh: å®½é«˜
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # x center
    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # y center
    y[:, 2] = x[:, 2] - x[:, 0]  # width
    y[:, 3] = x[:, 3] - x[:, 1]  # height
    return y


def xywh2xyxy(x):
    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
    """ç”¨åœ¨test.pyä¸­ æ“ä½œä¹‹å‰ è½¬ä¸ºxyxyæ‰å¯ä»¥è¿›è¡Œæ“ä½œ
    æ³¨æ„: xçš„æ­£æ–¹å‘ä¸ºå³é¢   yçš„æ­£æ–¹å‘ä¸ºä¸‹é¢
    Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where x1y1=top-left, x2y2=bottom-right
    :params x: [n, xywh] (x, y):
    :return y: [n, x1y1x2y2] (x1, y1): å·¦ä¸Šè§’  (x2, y2): å³ä¸‹è§’
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x
    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y
    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x
    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y
    return y


def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):
    # Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
    """ç”¨åœ¨datasets.pyçš„ LoadImagesAndLabelsç±»çš„__getitem__å‡½æ•°ã€load_mosaicã€load_mosaic9ç­‰å‡½æ•°ä¸­
    å°†xywh(normalized) -> x1y1x2y2   (x, y): ä¸­é—´ç‚¹  wh: å®½é«˜   (x1, y1): å·¦ä¸Šç‚¹  (x2, y2): å³ä¸‹ç‚¹
    Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + padw  # top left x
    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + padh  # top left y
    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + padw  # bottom right x
    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + padh  # bottom right y
    return y


def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):
    # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right
    """ç”¨åœ¨datasets.pyçš„ LoadImagesAndLabelsç±»çš„__getitem__å‡½æ•°ä¸­
    å°† x1y1x2y2 -> xywh(normalized)  (x1, y1): å·¦ä¸Šç‚¹  (x2, y2): å³ä¸‹ç‚¹  (x, y): ä¸­é—´ç‚¹  wh: å®½é«˜
    Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right
    """
    if clip:
        # æ˜¯å¦éœ€è¦å°†xçš„åæ ‡(x1y1x2y2)é™å®šåœ¨å°ºå¯¸(h, w)å†…
        clip_coords(x, (h - eps, w - eps))  # warning: inplace clip
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = ((x[:, 0] + x[:, 2]) / 2) / w  # x center
    y[:, 1] = ((x[:, 1] + x[:, 3]) / 2) / h  # y center
    y[:, 2] = (x[:, 2] - x[:, 0]) / w  # width
    y[:, 3] = (x[:, 3] - x[:, 1]) / h  # height
    return y


def xyn2xy(x, w=640, h=640, padw=0, padh=0):
    # Convert normalized segments into pixel segments, shape (n,2)
    """ç”¨åœ¨datasets.pyçš„load_mosaicå’Œload_mosaic9å‡½æ•°
    xy(normalized) -> xy
    Convert normalized segments into pixel segments, shape (n,2)
    """
    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
    y[:, 0] = w * x[:, 0] + padw  # top left x
    y[:, 1] = h * x[:, 1] + padh  # top left y
    return y


def segment2box(segment, width=640, height=640):
    # Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy)
    """ç”¨åœ¨datasets.pyæ–‡ä»¶ä¸­çš„random_perspectiveå‡½æ•°ä¸­
    å°†ä¸€ä¸ªå¤šè¾¹å½¢æ ‡ç­¾(ä¸æ˜¯çŸ©å½¢æ ‡ç­¾  åˆ°åº•æ˜¯å‡ è¾¹å½¢æœªçŸ¥)è½¬åŒ–ä¸ºä¸€ä¸ªçŸ©å½¢æ ‡ç­¾
    æ–¹æ³•: å¯¹å¤šè¾¹å½¢æ‰€æœ‰çš„ç‚¹x1y1 x2y2...  è·å–å…¶ä¸­çš„(x_min,y_min)å’Œ(x_max,y_max) ä½œä¸ºçŸ©å½¢labelçš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’
    Convert 1 segment label to 1 box label, applying inside-image constraint
    :params segment: ä¸€ä¸ªå¤šè¾¹å½¢æ ‡ç­¾ [n, 2] ä¼ å…¥è¿™ä¸ªå¤šè¾¹å½¢nä¸ªé¡¶ç‚¹çš„åæ ‡
    :params width: è¿™ä¸ªå¤šè¾¹å½¢æ‰€åœ¨å›¾ç‰‡çš„å®½åº¦
    :params height: è¿™ä¸ªå¤šè¾¹å½¢æ‰€åœ¨å›¾ç‰‡çš„é«˜åº¦
    :return çŸ©å½¢æ ‡ç­¾ [1, x_min+y_min+x_max+y_max]
    """
    # åˆ†åˆ«è·å–å½“å‰å¤šè¾¹å½¢ä¸­æ‰€æœ‰å¤šè¾¹å½¢ç‚¹çš„xå’Œyåæ ‡
    x, y = segment.T  # segment xy
    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)
    x, y, = x[inside], y[inside]
    return np.array([x.min(), y.min(), x.max(), y.max()]) if any(x) else np.zeros((1, 4))  # xyxy


def segments2boxes(segments):
    # Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)
    """ç”¨åœ¨datasets.pyæ–‡ä»¶ä¸­çš„verify_image_labelå‡½æ•°ä¸­
    å°†å¤šä¸ªå¤šè¾¹å½¢æ ‡ç­¾(ä¸æ˜¯çŸ©å½¢æ ‡ç­¾  åˆ°åº•æ˜¯å‡ è¾¹å½¢æœªçŸ¥)è½¬åŒ–ä¸ºå¤šä¸ªçŸ©å½¢æ ‡ç­¾
    Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)
    :params segments: [N, cls+x1y1+x2y2 ...]
    :return [N, cls+xywh]
    """
    boxes = []
    for s in segments:
        x, y = s.T  # segment xy
        boxes.append([x.min(), y.min(), x.max(), y.max()])  # cls, xyxy
    return xyxy2xywh(np.array(boxes))  # cls, xywh


def resample_segments(segments, n=1000):
    # Up-sample an (n,2) segment
    """ç”¨åœ¨datasets.pyæ–‡ä»¶ä¸­çš„random_perspectiveå‡½æ•°ä¸­
    å¯¹segmenté‡æ–°é‡‡æ ·ï¼Œæ¯”å¦‚è¯´segmentåæ ‡åªæœ‰100ä¸ªï¼Œé€šè¿‡interpå‡½æ•°å°†å…¶é‡‡æ ·ä¸ºnä¸ª(é»˜è®¤1000)
    :params segments: [N, x1x2...]
    :params n: é‡‡æ ·ä¸ªæ•°
    :return segments: [N, n/2, 2]
    """
    for i, s in enumerate(segments):
        x = np.linspace(0, len(s) - 1, n)
        xp = np.arange(len(s))
        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # segment xy
    return segments


def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
    # Rescale coords (xyxy) from img1_shape to img0_shape
    """ç”¨åœ¨detect.pyå’Œtest.pyä¸­  å°†é¢„æµ‹åæ ‡ä»feature mapæ˜ å°„å›åŸå›¾
    å°†åæ ‡coords(x1y1x2y2)ä»img1_shapeç¼©æ”¾åˆ°img0_shapeå°ºå¯¸
    Rescale coords (xyxy) from img1_shape to img0_shape
    :params img1_shape: coordsç›¸å¯¹äºçš„shapeå¤§å°
    :params coords: è¦è¿›è¡Œç¼©æ”¾çš„boxåæ ‡ä¿¡æ¯ x1y1x2y2  å·¦ä¸Šè§’ + å³ä¸‹è§’
    :params img0_shape: è¦å°†coordsç¼©æ”¾åˆ°ç›¸å¯¹çš„ç›®æ ‡shapeå¤§å°
    :params ratio_pad: ç¼©æ”¾æ¯”ä¾‹gainå’Œpadå€¼   Noneå°±å…ˆè®¡ç®—gainå’Œpadå€¼å†pad+scale  ä¸ä¸ºç©ºå°±ç›´æ¥pad+scale
    """
    # ratio_padä¸ºç©ºå°±å…ˆç®—æ”¾ç¼©æ¯”ä¾‹gainå’Œpadå€¼ calculate from img0_shape
    if ratio_pad is None:  # calculate from img0_shape
        # gain  = old / new  å–é«˜å®½ç¼©æ”¾æ¯”ä¾‹ä¸­è¾ƒå°çš„,ä¹‹åè¿˜å¯ä»¥å†pad  å¦‚æœç›´æ¥å–å¤§çš„, è£å‰ªå°±å¯èƒ½å‡å»ç›®æ ‡
        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new
        # wh padding  whä¸­æœ‰ä¸€ä¸ªä¸º0  ä¸»è¦æ˜¯padå¦ä¸€ä¸ª
        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding
    else:
        gain = ratio_pad[0][0]  # æŒ‡å®šæ¯”ä¾‹
        pad = ratio_pad[1]      # æŒ‡å®špadå€¼

    # å› ä¸ºpad = img1_shape - img0_shape æ‰€ä»¥è¦æŠŠå°ºå¯¸ä»img1 -> img0 å°±åŒæ ·ä¹Ÿéœ€è¦å‡å»pad
    # å¦‚æœimg1_shape>img0_shape  pad>0   coordsä»å¤§å°ºå¯¸ç¼©æ”¾åˆ°å°å°ºå¯¸ å‡å»pad ç¬¦åˆ
    # å¦‚æœimg1_shape<img0_shape  pad<0   coordsä»å°å°ºå¯¸ç¼©æ”¾åˆ°å¤§å°ºå¯¸ å‡å»pad ç¬¦åˆ
    coords[:, [0, 2]] -= pad[0]  # x padding
    coords[:, [1, 3]] -= pad[1]  # y padding
    # ç¼©æ”¾scale
    coords[:, :4] /= gain
    # é˜²æ­¢æ”¾ç¼©åçš„åæ ‡è¿‡ç•Œ è¾¹ç•Œå¤„ç›´æ¥å‰ªåˆ‡
    clip_coords(coords, img0_shape)
    return coords


def clip_coords(boxes, shape):
    # Clip bounding xyxy bounding boxes to image shape (height, width)
    """ç”¨åœ¨ä¸Šé¢çš„xyxy2xywhnã€save_one_boxdç­‰å‡½æ•°ä¸­
    å°†boxesçš„åæ ‡(x1y1x2y2 å·¦ä¸Šè§’å³ä¸‹è§’)é™å®šåœ¨å›¾åƒçš„å°ºå¯¸(img_shape hw)å†…
    Clip bounding x1y1x2y2 bounding boxes to image shape (height, width)
    """
    if isinstance(boxes, torch.Tensor):  # faster individually
        # .clamp_(min, max): å°†å–æ•´é™å®šåœ¨(min, max)ä¹‹é—´, è¶…å‡ºè¿™ä¸ªèŒƒå›´è‡ªåŠ¨åˆ’åˆ°è¾¹ç•Œä¸Š
        boxes[:, 0].clamp_(0, shape[1])  # x1
        boxes[:, 1].clamp_(0, shape[0])  # y1
        boxes[:, 2].clamp_(0, shape[1])  # x2
        boxes[:, 3].clamp_(0, shape[0])  # y2
    else:  # np.array (faster grouped)
        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])  # x1, x2
        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])  # y1, y2


def non_max_suppression(prediction,
                        conf_thres=0.25,
                        iou_thres=0.45,
                        classes=None,
                        agnostic=False,
                        multi_label=False,
                        labels=(),
                        max_det=300):
    """Non-Maximum Suppression (NMS) on inference results to reject overlapping bounding boxes

    Params:
            prediction: [batch, num_anchors(3ä¸ªyoloé¢„æµ‹å±‚), (x+y+w+h+1+num_classes)] = [1, 18900, 25]  3ä¸ªanchorçš„é¢„æµ‹ç»“æœæ€»å’Œ
            conf_thres: å…ˆè¿›è¡Œä¸€è½®ç­›é€‰ï¼Œå°†åˆ†æ•°è¿‡ä½çš„é¢„æµ‹æ¡†ï¼ˆ<conf_thresï¼‰åˆ é™¤ï¼ˆåˆ†æ•°ç½®0ï¼‰
            iou_thres: ioué˜ˆå€¼, å¦‚æœå…¶ä½™é¢„æµ‹æ¡†ä¸targetçš„iou>iou_thres, å°±å°†é‚£ä¸ªé¢„æµ‹æ¡†ç½®0
            classes: æ˜¯å¦nmsååªä¿ç•™ç‰¹å®šçš„ç±»åˆ« é»˜è®¤ä¸ºNone
            agnostic: è¿›è¡Œnmsæ˜¯å¦ä¹Ÿå»é™¤ä¸åŒç±»åˆ«ä¹‹é—´çš„æ¡† é»˜è®¤False
            multi_label: æ˜¯å¦æ˜¯å¤šæ ‡ç­¾  nc>1  ä¸€èˆ¬æ˜¯True
            labels: {list: bs} ç¬¬ä¸€å¼ å›¾ç‰‡çš„target[17, 5] ç¬¬äºŒå¼ [1, 5] ç¬¬ä¸‰å¼ [7, 5] ç¬¬å››å¼ [6, 5]
            max_det: æ¯å¼ å›¾ç‰‡çš„æœ€å¤§ç›®æ ‡ä¸ªæ•° é»˜è®¤1000
            merge: use merge-NMS å¤šä¸ªbounding boxç»™å®ƒä»¬ä¸€ä¸ªæƒé‡è¿›è¡Œèåˆ  é»˜è®¤False

    Returns:
         list of detections, on (n,6) tensor per image [xyxy, conf, cls]
    """

    bs = prediction.shape[0]  # batch size
    nc = prediction.shape[2] - 5  # number of classes
    xc = prediction[..., 4] > conf_thres  # candidates

    # Checks
    # Checks  æ£€æŸ¥ä¼ å…¥çš„conf_threså’Œiou_thresä¸¤ä¸ªé˜ˆå€¼æ˜¯å¦ç¬¦åˆèŒƒå›´
    assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'
    assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'
    # Settings   è®¾ç½®ä¸€äº›å˜é‡
    # min_wh = 2  # (pixels) minimum box width and height
    max_wh = 7680  # (pixels) maximum box width and height
    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()
    time_limit = 0.1 + 0.03 * bs  # seconds to quit after
    redundant = True  # require redundant detections
    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)
    merge = False  # use merge-NMS

    t = time.time()  # è®°å½•å½“å‰æ—¶åˆ»æ—¶é—´
    output = [torch.zeros((0, 6), device=prediction.device)] * bs
    for xi, x in enumerate(prediction):  # image index, image inference
        # Apply constraints
        # ç¬¬ä¸€å±‚è¿‡æ»¤ è™‘é™¤è¶…å°anchoræ ‡å’Œè¶…å¤§anchor   x=[18900, 25]
        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height
        # ç¬¬äºŒå±‚è¿‡æ»¤ æ ¹æ®conf_thresè™‘é™¤èƒŒæ™¯ç›®æ ‡(obj_conf<conf_thres 0.1çš„ç›®æ ‡ ç½®ä¿¡åº¦æä½çš„ç›®æ ‡)  x=[59, 25]
        x = x[xc[xi]]  # confidence

        # Cat apriori labels if autolabelling
        # {list: bs} ç¬¬ä¸€å¼ å›¾ç‰‡çš„target[17, 5] ç¬¬äºŒå¼ [1, 5] ç¬¬ä¸‰å¼ [7, 5] ç¬¬å››å¼ [6, 5]
        # Cat apriori labels if autolabelling è‡ªåŠ¨æ ‡æ³¨labelæ—¶è°ƒç”¨  ä¸€èˆ¬ä¸ç”¨
        # è‡ªåŠ¨æ ‡è®°åœ¨éå¸¸é«˜çš„ç½®ä¿¡é˜ˆå€¼ï¼ˆå³ 0.90 ç½®ä¿¡åº¦ï¼‰ä¸‹æ•ˆæœæœ€ä½³,è€Œ mAP è®¡ç®—ä¾èµ–äºéå¸¸ä½çš„ç½®ä¿¡é˜ˆå€¼ï¼ˆå³ 0.001ï¼‰æ¥æ­£ç¡®è¯„ä¼° PR æ›²çº¿ä¸‹çš„åŒºåŸŸã€‚
        if labels and len(labels[xi]):
            lb = labels[xi]
            v = torch.zeros((len(lb), nc + 5), device=x.device)
            v[:, :4] = lb[:, 1:5]  # box
            v[:, 4] = 1.0  # conf
            v[range(len(lb)), lb[:, 0].long() + 5] = 1.0  # cls  # v[:, targetç›¸åº”ä½ç½®cls,å…¶ä»–ä½ç½®ä¸º0]=1
            x = torch.cat((x, v), 0)  # x: [1204, 85] v: [17, 85] => x: [1221, 85]

        # If none remain process next image
        # ç»è¿‡å‰ä¸¤å±‚è¿‡æ»¤åå¦‚æœè¯¥feature mapæ²¡æœ‰ç›®æ ‡æ¡†äº†ï¼Œå°±ç»“æŸè¿™è½®ç›´æ¥è¿›è¡Œä¸‹ä¸€å¼ å›¾
        if not x.shape[0]:
            continue

        # Compute conf  è®¡ç®—conf_score
        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf

        # Box (center x, center y, width, height) to (x1, y1, x2, y2)
        box = xywh2xyxy(x[:, :4])

        # Detections matrix nx6 (xyxy, conf, cls)
        if multi_label:
            # ç¬¬ä¸‰è½®è¿‡æ»¤:é’ˆå¯¹æ¯ä¸ªç±»åˆ«score(obj_conf * cls_conf) > conf_thres    [59, 6] -> [51, 6]
            # è¿™é‡Œä¸€ä¸ªæ¡†æ˜¯æœ‰å¯èƒ½æœ‰å¤šä¸ªç‰©ä½“çš„ï¼Œæ‰€ä»¥è¦ç­›é€‰
            # nonzero: è·å¾—çŸ©é˜µä¸­çš„é0(True)æ•°æ®çš„ä¸‹æ ‡  a.t(): å°†açŸ©é˜µæ‹†å¼€
            # i: ä¸‹æ ‡ [43]   j: ç±»åˆ«index [43] è¿‡æ»¤äº†ä¸¤ä¸ªscoreå¤ªä½çš„
            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T
            # pred = [43, xyxy+score+class] [43, 6]
            # unsqueeze(1): [43] => [43, 1] add batch dimension
            # box[i]: [43,4] xyxy
            # pred[i, j + 5].unsqueeze(1): [43,1] score  å¯¹æ¯ä¸ªi,å–ç¬¬ï¼ˆj+5ï¼‰ä¸ªä½ç½®çš„å€¼ï¼ˆç¬¬jä¸ªclassçš„å€¼cla_confï¼‰
            # j.float().unsqueeze(1): [43,1] class
            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)
        else:  # best class only
            conf, j = x[:, 5:].max(1, keepdim=True)  # ä¸€ä¸ªç±»åˆ«ç›´æ¥å–åˆ†æ•°æœ€å¤§ç±»çš„å³å¯
            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]

        # Filter by class  æ˜¯å¦åªä¿ç•™ç‰¹å®šçš„ç±»åˆ«  é»˜è®¤None  ä¸æ‰§è¡Œè¿™é‡Œ
        if classes is not None:
            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]

        # Apply finite constraint
        # æ£€æµ‹æ•°æ®æ˜¯å¦ä¸ºæœ‰é™æ•° Apply finite constraint  è¿™è½®å¯æœ‰å¯æ— ï¼Œä¸€èˆ¬æ²¡ä»€ä¹ˆç”¨ æ‰€ä»¥è¿™é‡Œç»™ä»–æ³¨é‡Šäº†
        # if not torch.isfinite(x).all():
        #     x = x[torch.isfinite(x).all(1)]

        # Check shape
        n = x.shape[0]  # number of boxes
        if not n:  # no boxes  # å¦‚æœç»è¿‡ç¬¬ä¸‰è½®è¿‡æ»¤è¯¥feature mapæ²¡æœ‰ç›®æ ‡æ¡†äº†ï¼Œå°±ç»“æŸè¿™è½®ç›´æ¥è¿›è¡Œä¸‹ä¸€å¼ å›¾
            continue
        elif n > max_nms:  # excess boxes  # å¦‚æœç»è¿‡ç¬¬ä¸‰è½®è¿‡æ»¤è¯¥feature mapè¿˜è¦å¾ˆå¤šæ¡†(>max_nms)   å°±éœ€è¦æ’åº
            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence

        # Batched NMS
        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes
        # åšä¸ªåˆ‡ç‰‡ å¾—åˆ°boxeså’Œscores   ä¸åŒç±»åˆ«çš„boxä½ç½®ä¿¡æ¯åŠ ä¸Šä¸€ä¸ªå¾ˆå¤§çš„æ•°ä½†åˆä¸åŒçš„æ•°c
        # è¿™æ ·ä½œéæå¤§æŠ‘åˆ¶çš„æ—¶å€™ä¸åŒç±»åˆ«çš„æ¡†å°±ä¸ä¼šæºå’Œåˆ°ä¸€å—äº†  è¿™æ˜¯ä¸€ä¸ªä½œnmsæŒºå·§å¦™çš„æŠ€å·§
        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores
        # è¿”å›nmsè¿‡æ»¤åçš„bounding box(boxes)çš„ç´¢å¼•ï¼ˆé™åºæ’åˆ—ï¼‰
        # i=tensor([18, 19, 32, 25, 27])   nmsååªå‰©ä¸‹5ä¸ªé¢„æµ‹æ¡†äº†
        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS
        if i.shape[0] > max_det:  # limit detections
            i = i[:max_det]
        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)
            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)
            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix
            weights = iou * scores[None]  # box weights
            # bounding boxåˆå¹¶  å…¶å®å°±æ˜¯æŠŠæƒé‡å’Œæ¡†ç›¸ä¹˜å†é™¤ä»¥æƒé‡ä¹‹å’Œ
            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes
            if redundant:
                i = i[iou.sum(1) > 1]  # require redundancy

        output[xi] = x[i]  # æœ€ç»ˆè¾“å‡º   [5, 6]
        if (time.time() - t) > time_limit:
            LOGGER.warning(f'WARNING: NMS time limit {time_limit:.3f}s exceeded')
            break  # time limit exceeded

    return output


def strip_optimizer(f='best.pt', s=''):  # from utils.general import *; strip_optimizer()
    # Strip optimizer from 'f' to finalize training, optionally save as 's'
    """ç”¨åœ¨train.pyæ¨¡å‹è®­ç»ƒå®Œå
    å°†optimizerã€training_resultsã€updates...ä»ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶fä¸­åˆ é™¤
    Strip optimizer from 'f' to finalize training, optionally save as 's'
    :params f: ä¼ å…¥çš„åŸå§‹ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶
    :params s: åˆ é™¤optimizerç­‰å˜é‡åçš„æ¨¡å‹ä¿å­˜çš„åœ°å€ dir
    """
    # x: ä¸ºåŠ è½½è®­ç»ƒçš„æ¨¡å‹
    x = torch.load(f, map_location=torch.device('cpu'))
    # å¦‚æœæ¨¡å‹æ˜¯ema replace model with ema
    if x.get('ema'):
        x['model'] = x['ema']  # replace model with ema
    # ä»¥ä¸‹æ¨¡å‹è®­ç»ƒæ¶‰åŠåˆ°çš„è‹¥å¹²ä¸ªæŒ‡å®šå˜é‡ç½®ç©º
    for k in 'optimizer', 'best_fitness', 'wandb_id', 'ema', 'updates':  # keys
        x[k] = None
    x['epoch'] = -1    # æ¨¡å‹epochæ¢å¤åˆå§‹å€¼-1
    x['model'].half()  # to FP16
    for p in x['model'].parameters():
        p.requires_grad = False
    # ä¿å­˜æ¨¡å‹ x -> s/f
    torch.save(x, s or f)
    mb = os.path.getsize(s or f) / 1E6  # filesize
    LOGGER.info(f"Optimizer stripped from {f},{(' saved as %s,' % s) if s else ''} {mb:.1f}MB")


def print_mutation(results, hyp, save_dir, bucket, prefix=colorstr('evolve: ')):
    """ç”¨åœ¨train.pyçš„è¿›åŒ–è¶…å‚ç»“æŸå
    æ‰“å°è¿›åŒ–åçš„è¶…å‚ç»“æœå’Œresultsåˆ°evolve.txtå’Œhyp_evolved.yamlä¸­
    Print mutation results to evolve.txt (for use with train.py --evolve)
    :params hyp: è¿›åŒ–åçš„è¶…å‚ dict {28å¯¹ key:value}
    :params results: tuple(7)   (mp, mr, map50, map50:95, box_loss, obj_loss, cls_loss)
    :params yaml_file: è¦ä¿å­˜çš„è¿›åŒ–åçš„è¶…å‚æ–‡ä»¶å  runs\train\evolve\hyp_evolved.yaml
    :params bucket: ''
    """
    evolve_csv = save_dir / 'evolve.csv'
    evolve_yaml = save_dir / 'hyp_evolve.yaml'
    keys = ('metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/mAP_0.5:0.95', 'val/box_loss',
            'val/obj_loss', 'val/cls_loss') + tuple(hyp.keys())  # [results + hyps]
    keys = tuple(x.strip() for x in keys)
    vals = results + tuple(hyp.values())
    n = len(keys)

    # Download (optional)
    if bucket:
        url = f'gs://{bucket}/evolve.csv'
        if gsutil_getsize(url) > (evolve_csv.stat().st_size if evolve_csv.exists() else 0):
            os.system(f'gsutil cp {url} {save_dir}')  # download evolve.csv if larger than local

    # Log to evolve.csv
    s = '' if evolve_csv.exists() else (('%20s,' * n % keys).rstrip(',') + '\n')  # add header
    with open(evolve_csv, 'a') as f:
        f.write(s + ('%20.5g,' * n % vals).rstrip(',') + '\n')

    # Save yaml  ä¿å­˜yamlé…ç½®æ–‡ä»¶ ä¸º'hyp_evolved.yaml'
    with open(evolve_yaml, 'w') as f:
        data = pd.read_csv(evolve_csv)
        data = data.rename(columns=lambda x: x.strip())  # strip keys
        i = np.argmax(fitness(data.values[:, :4]))  #
        generations = len(data)
        f.write('# YOLOv5 Hyperparameter Evolution Results\n' + f'# Best generation: {i}\n' +
                f'# Last generation: {generations - 1}\n' + '# ' + ', '.join(f'{x.strip():>20s}' for x in keys[:7]) +
                '\n' + '# ' + ', '.join(f'{x:>20.5g}' for x in data.values[i, :7]) + '\n\n')
        yaml.safe_dump(data.loc[i][7:].to_dict(), f, sort_keys=False)

    # Print to screen
    LOGGER.info(prefix + f'{generations} generations finished, current result:\n' + prefix +
                ', '.join(f'{x.strip():>20s}' for x in keys) + '\n' + prefix + ', '.join(f'{x:20.5g}'
                                                                                         for x in vals) + '\n\n')

    if bucket:  # å¦‚æœéœ€è¦å­˜åˆ°è°·æ­Œäº‘ç›˜, å°±ä¸Šä¼   é»˜è®¤æ˜¯ä¸éœ€è¦çš„
        os.system(f'gsutil cp {evolve_csv} {evolve_yaml} gs://{bucket}')  # upload


def apply_classifier(x, model, img, im0):
    # Apply a second stage classifier to YOLO outputs
    # Example model = torchvision.models.__dict__['efficientnet_b0'](pretrained=True).to(device).eval()
    """ç”¨åœ¨detect.pyæ–‡ä»¶çš„nmsåç»§ç»­å¯¹feature mapé€å…¥model2 è¿›è¡ŒäºŒæ¬¡åˆ†ç±»   å‡ ä¹ä¸ä¼šç”¨å®ƒ
    å®šä¹‰äº†ä¸€ä¸ªäºŒçº§åˆ†ç±»å™¨æ¥å¤„ç†yoloçš„è¾“å‡º  å½“å‰å®ç°æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå‚è€ƒèµ·ç‚¹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒè‡ªè¡Œå®ç°æ­¤é¡¹
    æ¯”å¦‚ä½ æœ‰ç…§ç‰‡ä¸æ±½è½¦ä¸è½¦ç‰Œ, ä½ ç¬¬ä¸€æ¬¡å‰ªåˆ‡è½¦ç‰Œ, å¹¶å°†å…¶å‘é€åˆ°ç¬¬äºŒé˜¶æ®µåˆ†ç±»å™¨, ä»¥æ£€æµ‹å…¶ä¸­çš„å­—ç¬¦
    Apply a second stage classifier to yolo outputs
    https://github.com/ultralytics/yolov5/issues/2700  è¿™ä¸ªå‡½æ•°ä½¿ç”¨èµ·æ¥å¾ˆå®¹æ˜“å‡ºé”™ ä¸æ˜¯å¾ˆæ¨èä½¿ç”¨
    https://github.com/ultralytics/yolov5/issues/1472
    :params x: yoloå±‚çš„è¾“å‡º
    :params model: åˆ†ç±»æ¨¡å‹
    :params img: è¿›è¡Œresize + padä¹‹åçš„å›¾ç‰‡
    :params im0: åŸå°ºå¯¸çš„å›¾ç‰‡
    """
    im0 = [im0] if isinstance(im0, np.ndarray) else im0
    for i, d in enumerate(x):  # per image
        if d is not None and len(d):
            d = d.clone()

            # Reshape and pad cutouts
            b = xyxy2xywh(d[:, :4])  # boxes
            b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # rectangle to square
            b[:, 2:] = b[:, 2:] * 1.3 + 30  # pad
            d[:, :4] = xywh2xyxy(b).long()

            # Rescale boxes from img_size to im0 size
            scale_coords(img.shape[2:], d[:, :4], im0[i].shape)

            # Classes
            pred_cls1 = d[:, 5].long()  # åœ¨ä¹‹å‰çš„yoloæ¨¡å‹é¢„æµ‹çš„ç±»åˆ«
            ims = []
            for j, a in enumerate(d):  # per item
                cutout = im0[i][int(a[1]):int(a[3]), int(a[0]):int(a[2])]
                im = cv2.resize(cutout, (224, 224))  # BGR
                # cv2.imwrite('example%i.jpg' % j, cutout)

                im = im[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416
                im = np.ascontiguousarray(im, dtype=np.float32)  # uint8 to float32
                im /= 255  # 0 - 255 to 0.0 - 1.0
                ims.append(im)

            # ç”¨modelæ¨¡å‹è¿›è¡Œåˆ†ç±»é¢„æµ‹
            pred_cls2 = model(torch.Tensor(ims).to(d.device)).argmax(1)  # classifier prediction
            # ä¿ç•™é¢„æµ‹ä¸€è‡´çš„ç»“æœ
            x[i] = x[i][pred_cls1 == pred_cls2]  # retain matching class detections

    return x


def increment_path(path, exist_ok=False, sep='', mkdir=False):
    # Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.
    """è¿™æ˜¯ä¸ªç”¨å¤„ç‰¹åˆ«å¹¿æ³›çš„å‡½æ•° train.pyã€detect.pyã€test.pyç­‰éƒ½ä¼šç”¨åˆ°
    é€’å¢è·¯å¾„ å¦‚ run/train/exp --> runs/train/exp{sep}0, runs/exp{sep}1 etc.
    :params path: window path   run/train/exp
    :params exist_ok: False
    :params sep: expæ–‡ä»¶åçš„åç¼€  é»˜è®¤''
    :params mkdir: æ˜¯å¦åœ¨è¿™é‡Œåˆ›å»ºdir  False
    """
    path = Path(path)  # os-agnostic
    # å¦‚æœè¯¥æ–‡ä»¶å¤¹å·²ç»å­˜åœ¨ åˆ™å°†è·¯å¾„run/train/expä¿®æ”¹ä¸º runs/train/exp1
    if path.exists() and not exist_ok:
        # path.suffix å¾—åˆ°è·¯å¾„pathçš„åç¼€  ''
        # .with_suffix å°†è·¯å¾„æ·»åŠ ä¸€ä¸ªåç¼€ ''
        path, suffix = (path.with_suffix(''), path.suffix) if path.is_file() else (path, '')

        # Method 1
        for n in range(2, 9999):
            p = f'{path}{sep}{n}{suffix}'  # increment path
            if not os.path.exists(p):  #
                break
        path = Path(p)

        # Method 2 (deprecated)
        # dirs = glob.glob(f"{path}{sep}*")  # similar paths
        # matches = [re.search(rf"{path.stem}{sep}(\d+)", d) for d in dirs]
        # i = [int(m.groups()[0]) for m in matches if m]  # indices
        # n = max(i) + 1 if i else 2  # increment number
        # path = Path(f"{path}{sep}{n}{suffix}")  # increment path

    if mkdir:
        path.mkdir(parents=True, exist_ok=True)  # make directory

    return path


# OpenCV Chinese-friendly functions ------------------------------------------------------------------------------------
imshow_ = cv2.imshow  # copy to avoid recursion errors


def imread(path, flags=cv2.IMREAD_COLOR):
    return cv2.imdecode(np.fromfile(path, np.uint8), flags)


def imwrite(path, im):
    try:
        cv2.imencode(Path(path).suffix, im)[1].tofile(path)
        return True
    except Exception:
        return False


def imshow(path, im):
    imshow_(path.encode('unicode_escape').decode(), im)


cv2.imread, cv2.imwrite, cv2.imshow = imread, imwrite, imshow  # redefine

# Variables ------------------------------------------------------------------------------------------------------------
NCOLS = 0 if is_docker() else shutil.get_terminal_size().columns  # terminal window size for tqdm
